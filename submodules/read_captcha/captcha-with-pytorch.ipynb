{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fu/.virtualenvs/captcha-rsSqJZ6U/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import torch\n",
    "\n",
    "import const\n",
    "import my_datasets\n",
    "from my_models import MyResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_BATCH_SIZE = 64\n",
    "TEST_BATCH_SIZE = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, dataloader):\n",
    "    model.eval()\n",
    "\n",
    "    count_correct = 0\n",
    "    count_all = 0\n",
    "    _ACS = np.array(const.ALL_CHAR_SET)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for step, (img, _, label) in enumerate(dataloader):\n",
    "            img = img.cuda()\n",
    "            pred = model(img).reshape((-1, len(const.ALL_CHAR_SET), const.MAX_CAPTCHA)).cpu()\n",
    "        \n",
    "            c = [''.join(line) for line in _ACS[pred.argmax(axis=1)]]\n",
    "            count_correct += sum([(lambda x, y: (x == y))(x, y) for x, y in zip(c, label)])\n",
    "            count_all += len(c)\n",
    "    return count_correct / count_all\n",
    "\n",
    "def train(model, dataloader, loss_func, optimizer):\n",
    "    model.train()\n",
    "    loss_epoch = 0\n",
    "    for img, label_idx, label in dataloader:\n",
    "        img = img.cuda()\n",
    "        label_idx = label_idx.cuda()\n",
    "        pred = model(img).reshape((-1, len(const.ALL_CHAR_SET), const.MAX_CAPTCHA))\n",
    "\n",
    "        loss = loss_func(pred, label_idx)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_epoch += loss.item()\n",
    "    return loss_epoch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATA_NAMES = my_datasets.get_data_names()\n",
    "DATA_NAMES = list(my_datasets.DATA_DIRS.keys())\n",
    "#train_data_names = (DATA_NAMES[2], ) #'all'\n",
    "#train_dataloader_name = 'train_dataloader_'+str(train_dataloader_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('captcha-images', 'captcha-09az'), ('captcha-images', 'capitalized'), ('captcha-images', 'capital-color'), ('captcha-09az', 'capitalized'), ('captcha-09az', 'capital-color'), ('capitalized', 'capital-color')]\n"
     ]
    }
   ],
   "source": [
    "train_data_list = [tuple(DATA_NAMES[i] for i in sorted(indexes)) for indexes in [[0,1], [0,2], [0, 3], [1,2], [1,3], [2,3]]]\n",
    "print(train_data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "28b40e0cd24527661150bd99a1a8a244fe64d961"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('captcha-images', 'capital-color')]\n",
      "eopch: 0 loss: 412.602507352829 test: [0.0, 0.0, 0.0, 0.0] mean: 0.0\n",
      "eopch: 1 loss: 381.9094545841217 test: [0.0, 0.0, 0.0, 0.0] mean: 0.0\n",
      "eopch: 2 loss: 327.60688877105713 test: [0.0, 0.0, 0.0, 0.005] mean: 0.00125\n",
      "eopch: 3 loss: 247.60328996181488 test: [0.0, 0.0, 0.0, 0.03] mean: 0.0075\n",
      "eopch: 4 loss: 164.34826338291168 test: [0.0, 0.0, 0.0, 0.05] mean: 0.0125\n",
      "eopch: 5 loss: 100.85405504703522 test: [0.13, 0.0, 0.0, 0.32] mean: 0.1125\n",
      "eopch: 6 loss: 57.24165964126587 test: [0.324, 0.0, 0.0, 0.52] mean: 0.21100000000000002\n",
      "eopch: 7 loss: 33.789056062698364 test: [0.616, 0.0, 0.0, 0.855] mean: 0.36775\n",
      "eopch: 8 loss: 20.527918063104153 test: [0.176, 0.0, 0.0, 0.92] mean: 0.274\n",
      "eopch: 9 loss: 13.807498313486576 test: [0.006, 0.0, 0.0, 0.885] mean: 0.22275\n",
      "eopch: 10 loss: 10.519157011061907 test: [0.74, 0.0, 0.0, 0.965] mean: 0.42625\n"
     ]
    }
   ],
   "source": [
    "def process(model, loss_func, optimizer, train_data_names):\n",
    "    #train_dataloader = dataloaders[train_dataloader_name]\n",
    "    train_dataloader = my_datasets.get_dataloader(train_data_names, TRAIN_BATCH_SIZE, True)\n",
    "\n",
    "    model.train()\n",
    "    best_acc = 0\n",
    "    log = list()\n",
    "    save_dir = const.RECOGNIZER_DIR / '+'.join(train_data_names)\n",
    "    save_dir.mkdir(exist_ok=True)\n",
    "\n",
    "    for epoch in range(40):\n",
    "        loss = train(model, train_dataloader, loss_func, optimizer)\n",
    "        print('eopch:', epoch, 'loss:', loss, end=' ')\n",
    "\n",
    "        acc = [evaluate(model, my_datasets.get_dataloader((name, ), TEST_BATCH_SIZE, False)) for name in my_datasets.DATA_DIRS.keys()]\n",
    "        mean = sum(acc) / len(acc)\n",
    "        if mean > best_acc:\n",
    "            best_acc = mean\n",
    "        #    torch.save(model.state_dict(), str(const.RECOGNIZER_DIR/'{}.pt'.format(train_dataloader_name)))\n",
    "        torch.save(model.state_dict(), str(save_dir / '{}.pt'.format(epoch)))\n",
    "        log.append(dict(epoch=epoch, loss=loss, **{'acc{}'.format(i): val for i, val in enumerate(acc)}))\n",
    "        with (save_dir / 'log.json'.format()).open('w') as f:\n",
    "            json.dump(log, f)\n",
    "        print('test:', acc, 'mean:', mean)\n",
    "        if sum(acc) == 0:\n",
    "            continue\n",
    "        elif sum(acc) / len(train_data_names) > 0.75:\n",
    "            break\n",
    "\n",
    "#train_data_list = [tuple(DATA_NAMES[i] for i in sorted(indexes)) for indexes in [[0,1], [0,2], [1,2], [1,3], [2,3]]]\n",
    "train_data_list = [tuple(DATA_NAMES[i] for i in sorted(indexes)) for indexes in [[0, 3]]]\n",
    "\n",
    "print(train_data_list)\n",
    "\n",
    "for names in train_data_list:\n",
    "    out_features = len(const.ALL_CHAR_SET) * const.MAX_CAPTCHA\n",
    "    model = MyResNet(out_features)\n",
    "    model.cuda()\n",
    "    loss_func = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=5e-4)\n",
    "    process(model, loss_func, optimizer, names)\n",
    "    del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ee252c547d499faa13b42c8e5bacb5d07feea9557900722589fb9cc43695bfe0"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('captcha-rsSqJZ6U')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
